{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model_name = \"openai:gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a Topic Validator Agent.\n",
    "Your task is simple: determine if the given topic title is meaningful or not.\n",
    "return True or False only.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai import Agent\n",
    "\n",
    "\n",
    "agent = Agent(\n",
    "    model=model_name,\n",
    "    tools=[],  # No external tools needed for validation\n",
    "    deps_type=str,\n",
    "    output_type=str,\n",
    "    system_prompt=system_prompt,\n",
    "    retries=3  # Fewer retries as validation is simpler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelHTTPError",
     "evalue": "status_code: 401, model_name: gpt-4o-mini, body: {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************xswA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MyProjects\\th042025-main\\venv\\Lib\\site-packages\\pydantic_ai\\models\\openai.py:266\u001b[39m, in \u001b[36mOpenAIModel._completions_create\u001b[39m\u001b[34m(self, messages, stream, model_settings, model_request_parameters)\u001b[39m\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.client.chat.completions.create(\n\u001b[32m    267\u001b[39m         model=\u001b[38;5;28mself\u001b[39m._model_name,\n\u001b[32m    268\u001b[39m         messages=openai_messages,\n\u001b[32m    269\u001b[39m         n=\u001b[32m1\u001b[39m,\n\u001b[32m    270\u001b[39m         parallel_tool_calls=model_settings.get(\u001b[33m'\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m'\u001b[39m, NOT_GIVEN),\n\u001b[32m    271\u001b[39m         tools=tools \u001b[38;5;129;01mor\u001b[39;00m NOT_GIVEN,\n\u001b[32m    272\u001b[39m         tool_choice=tool_choice \u001b[38;5;129;01mor\u001b[39;00m NOT_GIVEN,\n\u001b[32m    273\u001b[39m         stream=stream,\n\u001b[32m    274\u001b[39m         stream_options={\u001b[33m'\u001b[39m\u001b[33minclude_usage\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m} \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m NOT_GIVEN,\n\u001b[32m    275\u001b[39m         stop=model_settings.get(\u001b[33m'\u001b[39m\u001b[33mstop_sequences\u001b[39m\u001b[33m'\u001b[39m, NOT_GIVEN),\n\u001b[32m    276\u001b[39m         max_completion_tokens=model_settings.get(\u001b[33m'\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m'\u001b[39m, NOT_GIVEN),\n\u001b[32m    277\u001b[39m         temperature=model_settings.get(\u001b[33m'\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m'\u001b[39m, NOT_GIVEN),\n\u001b[32m    278\u001b[39m         top_p=model_settings.get(\u001b[33m'\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m'\u001b[39m, NOT_GIVEN),\n\u001b[32m    279\u001b[39m         timeout=model_settings.get(\u001b[33m'\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m'\u001b[39m, NOT_GIVEN),\n\u001b[32m    280\u001b[39m         seed=model_settings.get(\u001b[33m'\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m'\u001b[39m, NOT_GIVEN),\n\u001b[32m    281\u001b[39m         presence_penalty=model_settings.get(\u001b[33m'\u001b[39m\u001b[33mpresence_penalty\u001b[39m\u001b[33m'\u001b[39m, NOT_GIVEN),\n\u001b[32m    282\u001b[39m         frequency_penalty=model_settings.get(\u001b[33m'\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m'\u001b[39m, NOT_GIVEN),\n\u001b[32m    283\u001b[39m         logit_bias=model_settings.get(\u001b[33m'\u001b[39m\u001b[33mlogit_bias\u001b[39m\u001b[33m'\u001b[39m, NOT_GIVEN),\n\u001b[32m    284\u001b[39m         reasoning_effort=model_settings.get(\u001b[33m'\u001b[39m\u001b[33mopenai_reasoning_effort\u001b[39m\u001b[33m'\u001b[39m, NOT_GIVEN),\n\u001b[32m    285\u001b[39m         user=model_settings.get(\u001b[33m'\u001b[39m\u001b[33mopenai_user\u001b[39m\u001b[33m'\u001b[39m, NOT_GIVEN),\n\u001b[32m    286\u001b[39m         extra_headers={\u001b[33m'\u001b[39m\u001b[33mUser-Agent\u001b[39m\u001b[33m'\u001b[39m: get_user_agent()},\n\u001b[32m    287\u001b[39m         extra_body=model_settings.get(\u001b[33m'\u001b[39m\u001b[33mextra_body\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m    288\u001b[39m     )\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m APIStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MyProjects\\th042025-main\\venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:2032\u001b[39m, in \u001b[36mAsyncCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   2031\u001b[39m validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m2032\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m   2033\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m/chat/completions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2034\u001b[39m     body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m   2035\u001b[39m         {\n\u001b[32m   2036\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,\n\u001b[32m   2037\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m   2038\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m\"\u001b[39m: audio,\n\u001b[32m   2039\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m   2040\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfunction_call\u001b[39m\u001b[33m\"\u001b[39m: function_call,\n\u001b[32m   2041\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfunctions\u001b[39m\u001b[33m\"\u001b[39m: functions,\n\u001b[32m   2042\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlogit_bias\u001b[39m\u001b[33m\"\u001b[39m: logit_bias,\n\u001b[32m   2043\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m: logprobs,\n\u001b[32m   2044\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmax_completion_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_completion_tokens,\n\u001b[32m   2045\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_tokens,\n\u001b[32m   2046\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m   2047\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodalities\u001b[39m\u001b[33m\"\u001b[39m: modalities,\n\u001b[32m   2048\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: n,\n\u001b[32m   2049\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m   2050\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprediction\u001b[39m\u001b[33m\"\u001b[39m: prediction,\n\u001b[32m   2051\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mpresence_penalty\u001b[39m\u001b[33m\"\u001b[39m: presence_penalty,\n\u001b[32m   2052\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mreasoning_effort\u001b[39m\u001b[33m\"\u001b[39m: reasoning_effort,\n\u001b[32m   2053\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m: response_format,\n\u001b[32m   2054\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: seed,\n\u001b[32m   2055\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m   2056\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m   2057\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m   2058\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m   2059\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstream_options\u001b[39m\u001b[33m\"\u001b[39m: stream_options,\n\u001b[32m   2060\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m   2061\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m   2062\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m   2063\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_logprobs\u001b[39m\u001b[33m\"\u001b[39m: top_logprobs,\n\u001b[32m   2064\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m   2065\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m   2066\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mweb_search_options\u001b[39m\u001b[33m\"\u001b[39m: web_search_options,\n\u001b[32m   2067\u001b[39m         },\n\u001b[32m   2068\u001b[39m         completion_create_params.CompletionCreateParamsStreaming\n\u001b[32m   2069\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[32m   2070\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m completion_create_params.CompletionCreateParamsNonStreaming,\n\u001b[32m   2071\u001b[39m     ),\n\u001b[32m   2072\u001b[39m     options=make_request_options(\n\u001b[32m   2073\u001b[39m         extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m   2074\u001b[39m     ),\n\u001b[32m   2075\u001b[39m     cast_to=ChatCompletion,\n\u001b[32m   2076\u001b[39m     stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   2077\u001b[39m     stream_cls=AsyncStream[ChatCompletionChunk],\n\u001b[32m   2078\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MyProjects\\th042025-main\\venv\\Lib\\site-packages\\openai\\_base_client.py:1805\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1802\u001b[39m opts = FinalRequestOptions.construct(\n\u001b[32m   1803\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1804\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1805\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MyProjects\\th042025-main\\venv\\Lib\\site-packages\\openai\\_base_client.py:1495\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[39m\n\u001b[32m   1493\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1495\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._request(\n\u001b[32m   1496\u001b[39m     cast_to=cast_to,\n\u001b[32m   1497\u001b[39m     options=options,\n\u001b[32m   1498\u001b[39m     stream=stream,\n\u001b[32m   1499\u001b[39m     stream_cls=stream_cls,\n\u001b[32m   1500\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1501\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MyProjects\\th042025-main\\venv\\Lib\\site-packages\\openai\\_base_client.py:1600\u001b[39m, in \u001b[36mAsyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls, retries_taken)\u001b[39m\n\u001b[32m   1599\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1600\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1602\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_response(\n\u001b[32m   1603\u001b[39m     cast_to=cast_to,\n\u001b[32m   1604\u001b[39m     options=options,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1608\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1609\u001b[39m )\n",
      "\u001b[31mAuthenticationError\u001b[39m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************xswA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mModelHTTPError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m agent.run(\u001b[33m\"\u001b[39m\u001b[33mRed cap buying in the Jumanji\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MyProjects\\th042025-main\\venv\\Lib\\site-packages\\pydantic_ai\\agent.py:436\u001b[39m, in \u001b[36mAgent.run\u001b[39m\u001b[34m(self, user_prompt, output_type, message_history, model, deps, model_settings, usage_limits, usage, infer_name, **_deprecated_kwargs)\u001b[39m\n\u001b[32m    424\u001b[39m     output_type = _deprecated_kwargs[\u001b[33m'\u001b[39m\u001b[33mresult_type\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter(\n\u001b[32m    427\u001b[39m     user_prompt=user_prompt,\n\u001b[32m    428\u001b[39m     output_type=output_type,\n\u001b[32m   (...)\u001b[39m\u001b[32m    434\u001b[39m     usage=usage,\n\u001b[32m    435\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agent_run:\n\u001b[32m--> \u001b[39m\u001b[32m436\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m agent_run:\n\u001b[32m    437\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m agent_run.result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mThe graph run did not finish properly\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MyProjects\\th042025-main\\venv\\Lib\\site-packages\\pydantic_ai\\agent.py:1745\u001b[39m, in \u001b[36mAgentRun.__anext__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1741\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__anext__\u001b[39m(\n\u001b[32m   1742\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1743\u001b[39m ) -> _agent_graph.AgentNode[AgentDepsT, OutputDataT] | End[FinalResult[OutputDataT]]:\n\u001b[32m   1744\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Advance to the next node automatically based on the last returned node.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1745\u001b[39m     next_node = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._graph_run.\u001b[34m__anext__\u001b[39m()\n\u001b[32m   1746\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _agent_graph.is_agent_node(next_node):\n\u001b[32m   1747\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m next_node\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MyProjects\\th042025-main\\venv\\Lib\\site-packages\\pydantic_graph\\graph.py:800\u001b[39m, in \u001b[36mGraphRun.__anext__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    797\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._next_node, End):\n\u001b[32m    798\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m800\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.next(\u001b[38;5;28mself\u001b[39m._next_node)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MyProjects\\th042025-main\\venv\\Lib\\site-packages\\pydantic_graph\\graph.py:773\u001b[39m, in \u001b[36mGraphRun.next\u001b[39m\u001b[34m(self, node)\u001b[39m\n\u001b[32m    771\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.persistence.record_run(node_snapshot_id):\n\u001b[32m    772\u001b[39m         ctx = GraphRunContext(\u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.deps)\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m         \u001b[38;5;28mself\u001b[39m._next_node = \u001b[38;5;28;01mawait\u001b[39;00m node.run(ctx)\n\u001b[32m    775\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._next_node, End):\n\u001b[32m    776\u001b[39m     \u001b[38;5;28mself\u001b[39m._snapshot_id = \u001b[38;5;28mself\u001b[39m._next_node.get_snapshot_id()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MyProjects\\th042025-main\\venv\\Lib\\site-packages\\pydantic_ai\\_agent_graph.py:271\u001b[39m, in \u001b[36mModelRequestNode.run\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._did_stream:\n\u001b[32m    267\u001b[39m     \u001b[38;5;66;03m# `self._result` gets set when exiting the `stream` contextmanager, so hitting this\u001b[39;00m\n\u001b[32m    268\u001b[39m     \u001b[38;5;66;03m# means that the stream was started but not finished before `run()` was called\u001b[39;00m\n\u001b[32m    269\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.AgentRunError(\u001b[33m'\u001b[39m\u001b[33mYou must finish streaming before calling run()\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m271\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_request(ctx)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MyProjects\\th042025-main\\venv\\Lib\\site-packages\\pydantic_ai\\_agent_graph.py:325\u001b[39m, in \u001b[36mModelRequestNode._make_request\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    323\u001b[39m model_settings, model_request_parameters = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._prepare_request(ctx)\n\u001b[32m    324\u001b[39m model_request_parameters = ctx.deps.model.customize_request_parameters(model_request_parameters)\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m model_response, request_usage = \u001b[38;5;28;01mawait\u001b[39;00m ctx.deps.model.request(\n\u001b[32m    326\u001b[39m     ctx.state.message_history, model_settings, model_request_parameters\n\u001b[32m    327\u001b[39m )\n\u001b[32m    328\u001b[39m ctx.state.usage.incr(_usage.Usage(), requests=\u001b[32m1\u001b[39m)\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._finish_handling(ctx, model_response, request_usage)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MyProjects\\th042025-main\\venv\\Lib\\site-packages\\pydantic_ai\\models\\openai.py:196\u001b[39m, in \u001b[36mOpenAIModel.request\u001b[39m\u001b[34m(self, messages, model_settings, model_request_parameters)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequest\u001b[39m(\n\u001b[32m    190\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    191\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[ModelMessage],\n\u001b[32m    192\u001b[39m     model_settings: ModelSettings | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    193\u001b[39m     model_request_parameters: ModelRequestParameters,\n\u001b[32m    194\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[ModelResponse, usage.Usage]:\n\u001b[32m    195\u001b[39m     check_allow_model_requests()\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._completions_create(\n\u001b[32m    197\u001b[39m         messages, \u001b[38;5;28;01mFalse\u001b[39;00m, cast(OpenAIModelSettings, model_settings \u001b[38;5;129;01mor\u001b[39;00m {}), model_request_parameters\n\u001b[32m    198\u001b[39m     )\n\u001b[32m    199\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_response(response), _map_usage(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MyProjects\\th042025-main\\venv\\Lib\\site-packages\\pydantic_ai\\models\\openai.py:291\u001b[39m, in \u001b[36mOpenAIModel._completions_create\u001b[39m\u001b[34m(self, messages, stream, model_settings, model_request_parameters)\u001b[39m\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m APIStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    290\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (status_code := e.status_code) >= \u001b[32m400\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ModelHTTPError(status_code=status_code, model_name=\u001b[38;5;28mself\u001b[39m.model_name, body=e.body) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    292\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mModelHTTPError\u001b[39m: status_code: 401, model_name: gpt-4o-mini, body: {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************xswA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}"
     ]
    }
   ],
   "source": [
    "result = await agent.run(\"Red cap buying in the Jumanji\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgentRunResult(output='False')\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgentRunResult(output='True')\n"
     ]
    }
   ],
   "source": [
    "result2 = await agent.run(\"Hacking\")\n",
    "print(result2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgentRunResult(output='False')\n"
     ]
    }
   ],
   "source": [
    "result3 = await agent.run(\"abs\")\n",
    "print(result3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
